{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PolicyEvaluation.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "9i10t3TrAN7U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y73qbBXiAXAM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#creating a grid environment\n",
        "def gridEnv(curr_state,action):\n",
        "  # In the 4*4 grid world state 0 and state 15 are terminal states\n",
        "  if(curr_state==0 or curr_state==15):\n",
        "    next_state=curr_state\n",
        "    reward=0\n",
        "  else:\n",
        "    #action 0 --> UP, action 1 --> DOWN, action 2 --> RIGHT, action 3 --> LEFT\n",
        "    #if the action results in the agent coming out of the grid then the curr_state will not change\n",
        "    reward=-1\n",
        "    if(action==0):\n",
        "      reward=-1\n",
        "      next_state=curr_state-4\n",
        "      if(next_state<0):\n",
        "        next_state=curr_state\n",
        "    elif(action==1):\n",
        "      next_state=curr_state+4\n",
        "      if(next_state>=16):\n",
        "        next_state=curr_state\n",
        "    elif(action==2):\n",
        "      if((curr_state+1)%4==0):\n",
        "        next_state=curr_state\n",
        "      else:\n",
        "        next_state=curr_state+1\n",
        "    elif(action==3):\n",
        "      if(curr_state%4==0):\n",
        "        next_state=curr_state\n",
        "      else:\n",
        "        next_state=curr_state-1\n",
        "#if the next_state is the terminanl state the reward is 0 otherwise -1\n",
        "  \n",
        "  #In this grid world the state transition probability for the given action and state is 1.\n",
        "  items=[1,next_state,reward]\n",
        "\n",
        "  return items\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uCI_Y1GuBFTX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def polyEval(policy,gamma=1,theta=0.00000001):\n",
        "  #Initializing the value function to zero\n",
        "  vf=np.zeros(16)\n",
        "  while True:\n",
        "    delta=0\n",
        "    #Iterating over the states\n",
        "    for curr_state in range(16):\n",
        "      new_vf=0\n",
        "      #iterating over the policy of a given state\n",
        "      for curr_action, p_action in enumerate(policy[curr_state]):\n",
        "        stateTprob,next_state,reward=gridEnv(curr_state,curr_action)\n",
        "        new_vf+=p_action*stateTprob*(reward+gamma*vf[next_state])\n",
        "      #new_vf is calcuated using Bellman-equation\n",
        "      #delta quantity is used to track the difference between initial VF and updated VF\n",
        "      delta=max(delta,np.abs(new_vf-vf[curr_state]))\n",
        "      vf[curr_state]=new_vf\n",
        "    #if delta becomes less than theta we come out of the loop\n",
        "    if(delta<theta):\n",
        "      break\n",
        "  #updated value function is returned\n",
        "  return vf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-df7Exy0QElQ",
        "colab_type": "code",
        "outputId": "cba1875f-20ad-4b13-c4da-f63f8f28e1fb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "#initializing random policy where each action has equal probability\n",
        "policy = np.ones([16, 4])/4\n",
        "vf = polyEval(policy)\n",
        "print(f'Value Function:\\n {vf.reshape(4,4)}')\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Value Function:\n",
            " [[  0.         -13.99999994 -19.99999991 -21.9999999 ]\n",
            " [-13.99999994 -17.99999992 -19.99999991 -19.99999992]\n",
            " [-19.99999991 -19.99999991 -17.99999993 -13.99999995]\n",
            " [-21.9999999  -19.99999992 -13.99999995   0.        ]]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}